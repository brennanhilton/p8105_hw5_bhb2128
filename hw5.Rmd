---
title: "hw5"
author: "Brennan Baker"
date: "November 6, 2018"
output:
  github_document:
    toc: true
---

```{r load packages}
library(tidyverse)
```

# Problem 1

### Load the data

```{r load data}
file_names = list.files(path = "./data") #make list of file names

load_data = function(x) {
  
  df = read_csv(file = str_c("./data/", x)) %>% 
    mutate(file = x) %>% #adds col with file name
    separate(file, into = c("file", "remove"), sep = "\\.") %>% #removes .csv from file col
    select(-remove) %>% 
    separate(file, into = c("arm", "subject_id"), sep = "_") #separate file col into arm and id
  df
  
}

loaded_data = map(file_names, load_data)

```

### Create final df from loaded data

```{r final df}
#initialize the final_df with one participants data
final_df = loaded_data[[1]] 

#add data from other participants by iterating through loaded data and binding rows
for (i in 2:length(loaded_data)) {
  final_df = bind_rows(final_df,loaded_data[[i]])
}

#tidy by gathering week, then remove redundant "week" in each value (turn "week_1" into "1")
#change con and exp for nicer plot labels
final_df = final_df %>% 
  gather(key = week, value = observation, week_1:week_8) %>% 
  separate(week, into = c("remove", "week"), sep = "_") %>%
  select(-remove) %>% 
  mutate(arm = replace(arm, arm == "con", "control"),
         arm = replace(arm, arm == "exp", "experimental"))
```

### Make spaghetti plot

```{r spaghetti plot}
final_df %>% 
  mutate(week = as.numeric(week)) %>% 
  ggplot(aes(x = week, y = observation, color = subject_id)) +
  geom_line() +
  facet_grid(~arm) +
  labs(
    title = "Observations over time in each arm",
    x = "Week",
    y = "Observation"
  ) + 
  theme_bw()
```

In the experimental arm, the value of the observations increased over time, while in the control arm, there was no change in observations over time. 

# Problem 2

### Load the data

```{r load homicides data}
homicides_df = read_csv(file = "./data-homicides-master/homicide-data.csv")
```

### Description of data

The raw data contains a row for each victim of a homicide. The information on each observation includes demographic information of the victim, the location of the killing (city, state, longitude, and latitude), the date of the homicide, and whether an arrest was made (disposition). Each row also has a unique id.

### Homicides by city

This code first uses summarize to make a df with the number of homicides by disposition. The second summarize function sums the total homicides and the number of unsolved homicides in each city.
```{r}
homicides_df = homicides_df %>% 
  mutate(city_state = str_c(city, ",\ ", state)) %>% 
  group_by(city_state, disposition) %>% 
  summarize(number_homicides = n()) %>%
  summarize(total_homicides = sum(number_homicides),
            unsolved_homicides = sum(number_homicides[disposition != "Closed by arrest"]))

```

There were 2827 total homicides in Baltimore, MD, of which 1825 were unsolved.

### prop.test

As an argument, prop.test takes a two-dimensional table (or matrix) with 2 columns, giving the counts of successes and failures, respectively. Alternatively, you can set x = numerator, n = denominator for the proportion. 
```{r}
proptest = unsolved %>% 
  mutate(solved_homicides = total_homicides - unsolved_homicides) %>% 
  filter(city_state == "Baltimore, MD") %>% 
  select(unsolved_homicides, solved_homicides)
```

Just for balitmore
```{r baltimore prop}
baltimore_proptest = prop.test(x = 1825, n = 2827)
broom::tidy(baltimore_proptest) %>% 
  select(estimate, conf.low, conf.high)
```



While dataset
```{r}
unsolved_homicides = function(x) {
  
  unsolved = homicides_df[["unsolved_homicides"]][[x]]
  unsolved
  
}

total_homicides = function(x) {
  
  total = homicides_df[["total_homicides"]][[x]]
  total
  
}

for (i in 1:nrow(homicides_df)) {
  homicides_df = homicides_df %>% 
    mutate(prop_test = list(
      broom::tidy(
        prop.test(x = unsolved_homicides(i), n = total_homicides(i))) %>% 
        select(estimate, conf.low, conf.high)))
}

```

```{r}
homicides_df %>% 
  mutate(prop_test = map())
```

Problem 2
The Washington Post has gathered data on homicides in 50 large U.S. cities and made the data available through a GitHub repository here. You can read their accompanying article here.

Describe the raw data. Create a city_state variable (e.g. “Baltimore, MD”) and then summarize within cities to obtain the total number of homicides and the number of unsolved homicides (those for which the disposition is “Closed without arrest” or “Open/No arrest”).

For the city of Baltimore, MD, use the prop.test function to estimate the proportion of homicides that are unsolved; save the output of prop.test as an R object, apply the broom::tidy to this object and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

Now run prop.test for each of the cities in your dataset, and extract both the proportion of unsolved homicides and the confidence interval for each. Do this within a “tidy” pipeline, making use of purrr::map, purrr::map2, list columns and  unnest as necessary to create a tidy dataframe with estimated proportions and CIs for each city.

Create a plot that shows the estimates and CIs for each city – check out geom_errorbar for a way to add error bars based on the upper and lower limits. Organize cities according to the proportion of unsolved homicides.

Survey
Please complete this survey regarding extra topics to cover at the end of the semester.