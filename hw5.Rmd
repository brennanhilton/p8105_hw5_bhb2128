---
title: "hw5"
author: "Brennan Baker"
date: "November 6, 2018"
output:
  github_document:
    toc: true
---

```{r load packages}
library(tidyverse)
```

# Problem 1

### Load the data

```{r load data, message = FALSE}
# Makes a data frame with 1 column of all file names from the data folder.
file_names = list.files(path = "./data") #make list of file names

# This function loads data into a data frame and saves information in the name of the file as two columns in the data frame, arm and subject_id.
load_data = function(x) {
  
  df = read_csv(file = str_c("./data/", x)) %>% 
    mutate(file = x) %>% #adds col with file name
    separate(file, into = c("file", "remove"), sep = "\\.") %>% #removes .csv from file col
    select(-remove) %>% 
    separate(file, into = c("arm", "subject_id"), sep = "_") #separate file col into arm and id
  df
  
}

# Map function that runs the load_data function on all file names saved in the file_names df, and daves the output as a list column in a new df called final_df. Then I unnest.
final_df = 
  tibble(file_names) %>% 
    mutate(data = map(file_names, load_data)) %>% 
      unnest()

```

### Create final df from loaded data

```{r tidy final df}
# Tidy by gathering week, then remove redundant "week" in each value (turn "week_1" into "1")
final_df = final_df %>% 
  gather(key = week, value = observation, week_1:week_8) %>% 
  separate(week, into = c("remove", "week"), sep = "_") %>%
  select(-remove) %>% 
  mutate(arm = replace(arm, arm == "con", "control"),
         arm = replace(arm, arm == "exp", "experimental"))
```

### Spaghetti plot

```{r spaghetti plot}
final_df %>% 
  mutate(week = as.numeric(week)) %>% 
  ggplot(aes(x = week, y = observation, color = subject_id)) +
  geom_line() +
  facet_grid(~arm) +
  labs(
    title = "Observations over time in each arm",
    x = "Week",
    y = "Observation"
  ) + 
  theme_bw()
```

In the experimental arm, the value of the observations increased over time, while in the control arm, there was no change in observations over time. 

# Problem 2

### Load the data

```{r load homicides data}
homicides_df = read_csv(file = "./data-homicides-master/homicide-data.csv")
```

### Description of data

The raw data contains a row for each victim of a homicide. The information on each observation includes demographic information of the victim, the location of the killing (city, state, longitude, and latitude), the date of the homicide, and whether an arrest was made (disposition). Each row / victim also has a unique id.

### Homicides by city

After crerating a new city_state variable, the code below uses summarize to make a df with the number of homicides in each city_state by disposition. The second summarize function sums the total homicides and the number of unsolved homicides in each city.
```{r homicides by city}
homicides_df = homicides_df %>% 
  mutate(city_state = str_c(city, ",\ ", state)) %>% 
  group_by(city_state, disposition) %>% 
  summarize(number_homicides = n()) %>%
  summarize(total_homicides = sum(number_homicides),
            unsolved_homicides = sum(number_homicides[disposition != "Closed by arrest"]))
homicides_df

```

For example, we can see from above that there were 2827 total homicides in Baltimore, MD, of which 1825 were unsolved.

### Prop. test

As an argument, prop.test takes a two-dimensional table (or matrix) with 2 columns, giving the counts of successes and failures, respectively. Alternatively, you can set x = numerator, n = denominator for the proportion. 

Prop.test just for balitmore. In the tibble below we can see the estimate and the CIs from the test. As a confirmation for the results, 1825/2827 does = 0.646 (the estimate).
```{r baltimore prop test}
baltimore_proptest = prop.test(x = 1825, n = 2827)
broom::tidy(baltimore_proptest) %>% 
  select(estimate, conf.low, conf.high)
```

Prop. tests for every city
```{r all prop tests}
#Below is a function that does a prop. test for a given row of the homicides_df.
prop_test_function = function(x) {
  
  test_result =
        broom::tidy(
          prop.test(x = homicides_df[["unsolved_homicides"]][[x]], homicides_df[["total_homicides"]][[x]])) %>% 
            select(estimate, conf.low, conf.high)
  test_result
}

#Below is a map function that runs the prop. test on each row and saves the results to a list column in a new data frame. Then I unnest the list column for graphing below.
homicides_df_prop_tests = homicides_df %>%
  mutate(prop_test = map(1:nrow(homicides_df), prop_test_function)) %>% 
  unnest() %>% 
  janitor::clean_names()

```

### Prop. test plot


```{r prop test plot}
homicides_df_prop_tests %>% 
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin=conf_low, ymax=conf_high)) +
  labs(
    title = "Unsolved cases by city",
    x = "City",
    y = "Proportion of cases unsolved"
  ) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

We can see from the plot that Tulsa, AL has an interesting looking confidence interval. From the data set I see that in Tulsa, AL, there was only 1 homicide (which was unsolved). Thus, the estimate should be 0 as it is in the graph, and the low sample size of homicides explains the wide confidence interval. 

It is likely that the data for Tulsa AL is incorrect. Tulsa AL does not exist and that one homicide probably belongs as a data point for Tulsa OK. Below I fix this problem

```{r remove Tulsa AL}
# Add 1 to the total homicides in Tulsa, OK
homicides_df_prop_tests[["total_homicides"]][[50]] = 584

# Remove the row for Tulsa, AL
homicides_df_prop_tests = homicides_df_prop_tests %>%
  filter(city_state != "Tulsa,\ AL")
# Re plot
homicides_df_prop_tests %>% 
  ggplot(aes(x = reorder(city_state, estimate), y = estimate)) +
  geom_point() +
  geom_errorbar(aes(ymin=conf_low, ymax=conf_high)) +
  labs(
    title = "Unsolved cases by city",
    x = "City",
    y = "Proportion of cases unsolved"
  ) + 
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

